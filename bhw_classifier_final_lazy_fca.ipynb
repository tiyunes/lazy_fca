{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import List, Dict, Tuple, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, recall_score, f1_score, precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_parquet('train_binarized.parquet')\n",
    "X_val = pd.read_parquet('val_binarized.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.read_parquet('y_train.parquet')\n",
    "y_val = pd.read_parquet('y_val.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pregnancies_ge_1</th>\n",
       "      <th>pregnancies_le_1</th>\n",
       "      <th>pregnancies_ge_3</th>\n",
       "      <th>pregnancies_le_3</th>\n",
       "      <th>pregnancies_ge_7</th>\n",
       "      <th>pregnancies_le_7</th>\n",
       "      <th>pregnancies_ge_9</th>\n",
       "      <th>pregnancies_le_9</th>\n",
       "      <th>glucose_ge_79</th>\n",
       "      <th>glucose_le_79</th>\n",
       "      <th>...</th>\n",
       "      <th>age_ge_24</th>\n",
       "      <th>age_le_24</th>\n",
       "      <th>age_ge_29</th>\n",
       "      <th>age_le_29</th>\n",
       "      <th>age_ge_40</th>\n",
       "      <th>age_le_40</th>\n",
       "      <th>age_ge_50</th>\n",
       "      <th>age_le_50</th>\n",
       "      <th>age_ge_60</th>\n",
       "      <th>age_le_60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pregnancies_ge_1  pregnancies_le_1  pregnancies_ge_3  pregnancies_le_3  \\\n",
       "357                 1                 0                 1                 0   \n",
       "73                  1                 0                 1                 0   \n",
       "352                 1                 0                 1                 1   \n",
       "497                 1                 0                 0                 1   \n",
       "145                 0                 1                 0                 1   \n",
       "..                ...               ...               ...               ...   \n",
       "71                  1                 0                 1                 0   \n",
       "106                 1                 1                 0                 1   \n",
       "270                 1                 0                 1                 0   \n",
       "435                 0                 1                 0                 1   \n",
       "102                 0                 1                 0                 1   \n",
       "\n",
       "     pregnancies_ge_7  pregnancies_le_7  pregnancies_ge_9  pregnancies_le_9  \\\n",
       "357                 1                 0                 1                 0   \n",
       "73                  0                 1                 0                 1   \n",
       "352                 0                 1                 0                 1   \n",
       "497                 0                 1                 0                 1   \n",
       "145                 0                 1                 0                 1   \n",
       "..                ...               ...               ...               ...   \n",
       "71                  0                 1                 0                 1   \n",
       "106                 0                 1                 0                 1   \n",
       "270                 1                 0                 1                 0   \n",
       "435                 0                 1                 0                 1   \n",
       "102                 0                 1                 0                 1   \n",
       "\n",
       "     glucose_ge_79  glucose_le_79  ...  age_ge_24  age_le_24  age_ge_29  \\\n",
       "357              1              0  ...          1          0          1   \n",
       "73               1              0  ...          0          1          0   \n",
       "352              0              1  ...          1          0          1   \n",
       "497              1              0  ...          1          0          0   \n",
       "145              1              0  ...          0          1          0   \n",
       "..             ...            ...  ...        ...        ...        ...   \n",
       "71               1              0  ...          1          0          0   \n",
       "106              1              0  ...          1          0          0   \n",
       "270              1              0  ...          1          0          1   \n",
       "435              1              0  ...          1          0          1   \n",
       "102              1              0  ...          0          1          0   \n",
       "\n",
       "     age_le_29  age_ge_40  age_le_40  age_ge_50  age_le_50  age_ge_60  \\\n",
       "357          0          1          0          0          1          0   \n",
       "73           1          0          1          0          1          0   \n",
       "352          0          1          0          0          1          0   \n",
       "497          1          0          1          0          1          0   \n",
       "145          1          0          1          0          1          0   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "71           1          0          1          0          1          0   \n",
       "106          1          0          1          0          1          0   \n",
       "270          0          0          1          0          1          0   \n",
       "435          1          0          1          0          1          0   \n",
       "102          1          0          1          0          1          0   \n",
       "\n",
       "     age_le_60  \n",
       "357          1  \n",
       "73           1  \n",
       "352          1  \n",
       "497          1  \n",
       "145          1  \n",
       "..         ...  \n",
       "71           1  \n",
       "106          1  \n",
       "270          1  \n",
       "435          1  \n",
       "102          1  \n",
       "\n",
       "[576 rows x 78 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>357</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>576 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     outcome\n",
       "357        1\n",
       "73         0\n",
       "352        0\n",
       "497        0\n",
       "145        0\n",
       "..       ...\n",
       "71         0\n",
       "106        0\n",
       "270        1\n",
       "435        1\n",
       "102        0\n",
       "\n",
       "[576 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pos = X_train[y_train['outcome'] == 1]\n",
    "X_train_neg = X_train[y_train['outcome'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((199, 78), (377, 78))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pos.shape, X_train_neg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>668</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>192 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     prediction\n",
       "668           0\n",
       "324           0\n",
       "624           0\n",
       "690           0\n",
       "473           0\n",
       "..          ...\n",
       "554           0\n",
       "319           0\n",
       "594           0\n",
       "6             0\n",
       "615           0\n",
       "\n",
       "[192 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_pred = pd.DataFrame(np.zeros_like(y_val), columns=['prediction'], index=y_val.index)\n",
    "y_val_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyClassifierFCA:\n",
    "    def __init__(self):\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "\n",
    "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def classify_sample(self, sample: pd.Series) -> Any:\n",
    "        # Split X_train into positive and negative classes\n",
    "        X_train_positive = self.X_train[y_train['outcome'] == 1]\n",
    "        X_train_negative = self.X_train[y_train['outcome'] == 0]\n",
    "        \n",
    "        positive_classifiers = 0\n",
    "        negative_classifiers = 0\n",
    "        \n",
    "        # Function to check if intersection with a train sample is a positive classifier\n",
    "        def is_positive_classifier(intersection):\n",
    "            # Find samples in X_train_positive that contain the intersection\n",
    "            num_positive = ((X_train_positive | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            num_negative = ((X_train_negative | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            return num_negative == 0 and num_positive > 1\n",
    "        \n",
    "        # Function to check if intersection is a negative classifier\n",
    "        def is_negative_classifier(intersection):\n",
    "            # Find samples in X_train_negative that contain the intersection\n",
    "            num_positive = ((X_train_positive | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            num_negative = ((X_train_negative | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            return num_positive == 0 and num_negative > 1\n",
    "        \n",
    "        # Check for positive classifiers by intersecting sample with each positive object\n",
    "        for _, pos_sample in X_train_positive.iterrows():\n",
    "            intersection = sample & pos_sample\n",
    "            if is_positive_classifier(intersection):\n",
    "                positive_classifiers += 1\n",
    "\n",
    "        # Check for negative classifiers by intersecting sample with each negative object\n",
    "        for _, neg_sample in X_train_negative.iterrows():\n",
    "            intersection = sample & neg_sample\n",
    "            if is_negative_classifier(intersection):\n",
    "                negative_classifiers += 1\n",
    "\n",
    "        # Determine the class based on the number of classifiers\n",
    "        if positive_classifiers > negative_classifiers:\n",
    "            # print(f\"sample {sample.name} is classified as 1, {positive_classifiers=}, {negative_classifiers=}\")\n",
    "            return 1, positive_classifiers  # Predict positive\n",
    "            \n",
    "        elif negative_classifiers > positive_classifiers:\n",
    "            # print(f\"sample {sample.name} is classified as 0, {positive_classifiers=}, {negative_classifiers=}\")\n",
    "            return 0, negative_classifiers  # Predict negative\n",
    "\n",
    "        else:\n",
    "            # If equal, you can decide on a rule, like defaulting to 0 or 1, or returning 'undetermined'\n",
    "            # print(f\"sample {sample.name} is classified as 1, default, {positive_classifiers=}, {negative_classifiers=}\")\n",
    "        \n",
    "            return 1, positive_classifiers  # or 0, depending on the choice\n",
    "\n",
    "\n",
    "    def predict(self, X_test: pd.DataFrame) -> List[Any]:\n",
    "        # List to store predictions for each test sample\n",
    "        predictions = []\n",
    "        classifiers = []\n",
    "        \n",
    "        # Iterate through each sample in X_test\n",
    "        for _, sample in X_test.iterrows():\n",
    "            # Classify the sample and append the result to predictions\n",
    "            prediction, n_clfs = self.classify_sample(sample)\n",
    "            predictions.append(prediction)\n",
    "            classifiers.append(n_clfs)\n",
    "        \n",
    "        self.avg_n_clfs = np.mean(classifiers)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_binary_classification(y_val, y_pred):\n",
    "    \"\"\"\n",
    "    Evaluate a binary classification model's performance using sklearn metrics.\n",
    "    \n",
    "    Parameters:\n",
    "    y_val (array-like): Ground truth binary labels (0 or 1).\n",
    "    y_pred (array-like): Predicted binary labels (0 or 1).\n",
    "    \n",
    "    Prints:\n",
    "    - Confusion Matrix components (TP, TN, FP, FN)\n",
    "    - Specificity (True Negative Rate)\n",
    "    - Negative Predictive Value (NPV)\n",
    "    - False Positive Rate (FPR)\n",
    "    - False Discovery Rate (FDR)\n",
    "    - Accuracy\n",
    "    - Precision\n",
    "    - Recall (True Positive Rate)\n",
    "    - F1 Score\n",
    "    \"\"\"\n",
    "    # Confusion matrix components\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "\n",
    "    # Metrics calculations\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0  # True Negative Rate\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0  # Negative Predictive Value\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0  # False Positive Rate\n",
    "    fdr = fp / (fp + tp) if (fp + tp) > 0 else 0  # False Discovery Rate\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"True Positive (TP): {tp}\")\n",
    "    print(f\"True Negative (TN): {tn}\")\n",
    "    print(f\"False Positive (FP): {fp}\")\n",
    "    print(f\"False Negative (FN): {fn}\")\n",
    "    print(f\"True Negative Rate (Specificity): {specificity:.4f}\")\n",
    "    print(f\"Negative Predictive Value (NPV): {npv:.4f}\")\n",
    "    print(f\"False Positive Rate (FPR): {fpr:.4f}\")\n",
    "    print(f\"False Discovery Rate (FDR): {fdr:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall (True Positive Rate): {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LazyClassifierFCA()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2min 3s\n",
      "Wall time: 3min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = classifier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive (TP): 26\n",
      "True Negative (TN): 112\n",
      "False Positive (FP): 11\n",
      "False Negative (FN): 43\n",
      "True Negative Rate (Specificity): 0.9106\n",
      "Negative Predictive Value (NPV): 0.7226\n",
      "False Positive Rate (FPR): 0.0894\n",
      "False Discovery Rate (FDR): 0.2973\n",
      "Accuracy: 0.7188\n",
      "Precision: 0.7027\n",
      "Recall (True Positive Rate): 0.3768\n",
      "F1 Score: 0.4906\n"
     ]
    }
   ],
   "source": [
    "evaluate_binary_classification(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.91      0.81       123\n",
      "           1       0.70      0.38      0.49        69\n",
      "\n",
      "    accuracy                           0.72       192\n",
      "   macro avg       0.71      0.64      0.65       192\n",
      "weighted avg       0.72      0.72      0.69       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111.10416666666667"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.avg_n_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyClassifierFCA2:\n",
    "    def __init__(self):\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        # self.max_counter_examples = max_counter_examples\n",
    "\n",
    "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def classify_sample(self, sample: pd.Series) -> Any:\n",
    "        # Split X_train into positive and negative classes\n",
    "        X_train_positive = self.X_train[y_train['outcome'] == 1]\n",
    "        X_train_negative = self.X_train[y_train['outcome'] == 0]\n",
    "        \n",
    "        positive_classifiers = 0\n",
    "        negative_classifiers = 0\n",
    "        \n",
    "        # Function to check if intersection with a train sample is a positive classifier\n",
    "        def is_positive_classifier(intersection):\n",
    "            # Find samples in X_train_positive that contain the intersection\n",
    "            num_positive = ((X_train_positive | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            num_negative = ((X_train_negative | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            return num_negative == 0 and num_positive > 1\n",
    "        \n",
    "        # Function to check if intersection is a negative classifier\n",
    "        def is_negative_classifier(intersection):\n",
    "            # Find samples in X_train_negative that contain the intersection\n",
    "            num_positive = ((X_train_positive | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            num_negative = ((X_train_negative | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            return num_positive == 0 and num_negative > 1\n",
    "        \n",
    "        # Check for positive classifiers by intersecting sample with each positive object\n",
    "        for _, pos_sample in X_train_positive.iterrows():\n",
    "            intersection = sample & pos_sample\n",
    "            if is_positive_classifier(intersection):\n",
    "                positive_classifiers += 1\n",
    "\n",
    "        # Check for negative classifiers by intersecting sample with each negative object\n",
    "        for _, neg_sample in X_train_negative.iterrows():\n",
    "            intersection = sample & neg_sample\n",
    "            if is_negative_classifier(intersection):\n",
    "                negative_classifiers += 1\n",
    "\n",
    "        # Determine the class based on the number of classifiers\n",
    "        if positive_classifiers / X_train_positive.shape[0] > negative_classifiers / X_train_negative.shape[0]:\n",
    "            # print(f\"sample {sample.name} is classified as 1, {positive_classifiers=}, {negative_classifiers=}\")\n",
    "            return 1, positive_classifiers  # Predict positive\n",
    "            \n",
    "        elif negative_classifiers / X_train_negative.shape[0] > positive_classifiers / X_train_positive.shape[0]:\n",
    "            # print(f\"sample {sample.name} is classified as 0, {positive_classifiers=}, {negative_classifiers=}\")\n",
    "            return 0, negative_classifiers  # Predict negative\n",
    "\n",
    "        else:\n",
    "            # If equal, you can decide on a rule, like defaulting to 0 or 1, or returning 'undetermined'\n",
    "            # print(f\"sample {sample.name} is classified as 1, default, {positive_classifiers=}, {negative_classifiers=}\")\n",
    "        \n",
    "            return 1, positive_classifiers  # or 0, depending on the choice\n",
    "\n",
    "\n",
    "    def predict(self, X_test: pd.DataFrame) -> List[Any]:\n",
    "        # List to store predictions for each test sample\n",
    "        predictions = []\n",
    "        classifiers = []\n",
    "        \n",
    "        # Iterate through each sample in X_test\n",
    "        for _, sample in X_test.iterrows():\n",
    "            # Classify the sample and append the result to predictions\n",
    "            prediction, n_clfs = self.classify_sample(sample)\n",
    "            predictions.append(prediction)\n",
    "            classifiers.append(n_clfs)\n",
    "        \n",
    "        self.avg_n_clfs = np.mean(classifiers)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier2 = LazyClassifierFCA2()\n",
    "classifier2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 54.3 s\n",
      "Wall time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred2 = classifier2.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive (TP): 40\n",
      "True Negative (TN): 103\n",
      "False Positive (FP): 20\n",
      "False Negative (FN): 29\n",
      "True Negative Rate (Specificity): 0.8374\n",
      "Negative Predictive Value (NPV): 0.7803\n",
      "False Positive Rate (FPR): 0.1626\n",
      "False Discovery Rate (FDR): 0.3333\n",
      "Accuracy: 0.7448\n",
      "Precision: 0.6667\n",
      "Recall (True Positive Rate): 0.5797\n",
      "F1 Score: 0.6202\n"
     ]
    }
   ],
   "source": [
    "evaluate_binary_classification(y_val, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.234375"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier2.avg_n_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_val, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81       123\n",
      "           1       0.67      0.58      0.62        69\n",
      "\n",
      "    accuracy                           0.74       192\n",
      "   macro avg       0.72      0.71      0.71       192\n",
      "weighted avg       0.74      0.74      0.74       192\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyClassifierFCA3:\n",
    "    def __init__(self, max_counter_examples=5, min_cardinality=25):\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        self.max_counter_examples = max_counter_examples\n",
    "        self.min_cardinality = min_cardinality\n",
    "\n",
    "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def classify_sample(self, sample: pd.Series) -> Any:\n",
    "        # Split X_train into positive and negative classes\n",
    "        X_train_positive = self.X_train[y_train['outcome'] == 1]\n",
    "        X_train_negative = self.X_train[y_train['outcome'] == 0]\n",
    "        \n",
    "        positive_classifiers = 0\n",
    "        negative_classifiers = 0\n",
    "        \n",
    "        # Function to check if intersection with a train sample is a positive classifier\n",
    "        def is_positive_classifier(intersection):\n",
    "            # Find samples in X_train_positive that contain the intersection\n",
    "            num_positive = ((X_train_positive | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            num_negative = ((X_train_negative | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            return num_negative < self.max_counter_examples and num_positive > 1\n",
    "        \n",
    "        # Function to check if intersection is a negative classifier\n",
    "        def is_negative_classifier(intersection):\n",
    "            # Find samples in X_train_negative that contain the intersection\n",
    "            num_positive = ((X_train_positive | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            num_negative = ((X_train_negative | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            return num_positive < self.max_counter_examples and num_negative > 1\n",
    "        \n",
    "        # Check for positive classifiers by intersecting sample with each positive object\n",
    "        for _, pos_sample in X_train_positive.iterrows():\n",
    "            intersection = sample & pos_sample\n",
    "            if is_positive_classifier(intersection) and intersection.sum() >= self.min_cardinality:\n",
    "                positive_classifiers += 1\n",
    "\n",
    "        # Check for negative classifiers by intersecting sample with each negative object\n",
    "        for _, neg_sample in X_train_negative.iterrows():\n",
    "            intersection = sample & neg_sample\n",
    "            if is_negative_classifier(intersection) and intersection.sum() >= self.min_cardinality:\n",
    "                negative_classifiers += 1\n",
    "\n",
    "        # Determine the class based on the number of classifiers\n",
    "        if positive_classifiers / X_train_positive.shape[0] > negative_classifiers / X_train_negative.shape[0]:\n",
    "            # print(f\"sample {sample.name} is classified as 1, {positive_classifiers=}, {negative_classifiers=}\")\n",
    "            return 1, positive_classifiers  # Predict positive\n",
    "            \n",
    "        elif negative_classifiers / X_train_negative.shape[0] > positive_classifiers / X_train_positive.shape[0]:\n",
    "            # print(f\"sample {sample.name} is classified as 0, {positive_classifiers=}, {negative_classifiers=}\")\n",
    "            return 0, negative_classifiers  # Predict negative\n",
    "\n",
    "        else:\n",
    "            # If equal, you can decide on a rule, like defaulting to 0 or 1, or returning 'undetermined'\n",
    "            # print(f\"sample {sample.name} is classified as 1, default, {positive_classifiers=}, {negative_classifiers=}\")\n",
    "        \n",
    "            return 1, positive_classifiers  # or 0, depending on the choice\n",
    "\n",
    "\n",
    "    def predict(self, X_test: pd.DataFrame) -> List[Any]:\n",
    "        # List to store predictions for each test sample\n",
    "        predictions = []\n",
    "        classifiers = []\n",
    "        \n",
    "        # Iterate through each sample in X_test\n",
    "        for _, sample in X_test.iterrows():\n",
    "            # Classify the sample and append the result to predictions\n",
    "            prediction, n_clfs = self.classify_sample(sample)\n",
    "            predictions.append(prediction)\n",
    "            classifiers.append(n_clfs)\n",
    "        \n",
    "        self.avg_n_clfs = np.mean(classifiers)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cardinalities = [20, 22, 24, 26, 28, 30]\n",
    "f1_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_cardinalities2 = [10, 12, 14, 16, 18, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics with min_cardinality = 10\n",
      "True Positive (TP): 40\n",
      "True Negative (TN): 103\n",
      "False Positive (FP): 20\n",
      "False Negative (FN): 29\n",
      "True Negative Rate (Specificity): 0.8374\n",
      "Negative Predictive Value (NPV): 0.7803\n",
      "False Positive Rate (FPR): 0.1626\n",
      "False Discovery Rate (FDR): 0.3333\n",
      "Accuracy: 0.7448\n",
      "Precision: 0.6667\n",
      "Recall (True Positive Rate): 0.5797\n",
      "F1 Score: 0.6202\n",
      "\n",
      "\n",
      "Metrics with min_cardinality = 12\n",
      "True Positive (TP): 40\n",
      "True Negative (TN): 103\n",
      "False Positive (FP): 20\n",
      "False Negative (FN): 29\n",
      "True Negative Rate (Specificity): 0.8374\n",
      "Negative Predictive Value (NPV): 0.7803\n",
      "False Positive Rate (FPR): 0.1626\n",
      "False Discovery Rate (FDR): 0.3333\n",
      "Accuracy: 0.7448\n",
      "Precision: 0.6667\n",
      "Recall (True Positive Rate): 0.5797\n",
      "F1 Score: 0.6202\n",
      "\n",
      "\n",
      "Metrics with min_cardinality = 14\n",
      "True Positive (TP): 40\n",
      "True Negative (TN): 103\n",
      "False Positive (FP): 20\n",
      "False Negative (FN): 29\n",
      "True Negative Rate (Specificity): 0.8374\n",
      "Negative Predictive Value (NPV): 0.7803\n",
      "False Positive Rate (FPR): 0.1626\n",
      "False Discovery Rate (FDR): 0.3333\n",
      "Accuracy: 0.7448\n",
      "Precision: 0.6667\n",
      "Recall (True Positive Rate): 0.5797\n",
      "F1 Score: 0.6202\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m classifier3 \u001b[38;5;241m=\u001b[39m LazyClassifierFCA3(max_counter_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, min_cardinality\u001b[38;5;241m=\u001b[39mmin_cardinality)\n\u001b[0;32m      3\u001b[0m classifier3\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m----> 4\u001b[0m y_pred3 \u001b[38;5;241m=\u001b[39m \u001b[43mclassifier3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMetrics with min_cardinality = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmin_cardinality\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m evaluate_binary_classification(y_val, y_pred3)\n",
      "Cell \u001b[1;32mIn[14], line 70\u001b[0m, in \u001b[0;36mLazyClassifierFCA3.predict\u001b[1;34m(self, X_test)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Iterate through each sample in X_test\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, sample \u001b[38;5;129;01min\u001b[39;00m X_test\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Classify the sample and append the result to predictions\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     prediction, n_clfs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassify_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     71\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(prediction)\n\u001b[0;32m     72\u001b[0m     classifiers\u001b[38;5;241m.\u001b[39mappend(n_clfs)\n",
      "Cell \u001b[1;32mIn[14], line 43\u001b[0m, in \u001b[0;36mLazyClassifierFCA3.classify_sample\u001b[1;34m(self, sample)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, neg_sample \u001b[38;5;129;01min\u001b[39;00m X_train_negative\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     42\u001b[0m     intersection \u001b[38;5;241m=\u001b[39m sample \u001b[38;5;241m&\u001b[39m neg_sample\n\u001b[1;32m---> 43\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_negative_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintersection\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m intersection\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_cardinality:\n\u001b[0;32m     44\u001b[0m         negative_classifiers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Determine the class based on the number of classifiers\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 31\u001b[0m, in \u001b[0;36mLazyClassifierFCA3.classify_sample.<locals>.is_negative_classifier\u001b[1;34m(intersection)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_negative_classifier\u001b[39m(intersection):\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# Find samples in X_train_negative that contain the intersection\u001b[39;00m\n\u001b[0;32m     30\u001b[0m     num_positive \u001b[38;5;241m=\u001b[39m ((X_train_positive \u001b[38;5;241m|\u001b[39m (\u001b[38;5;241m~\u001b[39mintersection\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mbool\u001b[39m))\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint32)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mall(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m---> 31\u001b[0m     num_negative \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_negative\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m~\u001b[39;49m\u001b[43mintersection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m num_positive \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_counter_examples \u001b[38;5;129;01mand\u001b[39;00m num_negative \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\yunes\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11628\u001b[0m, in \u001b[0;36mDataFrame.all\u001b[1;34m(self, axis, bool_only, skipna, **kwargs)\u001b[0m\n\u001b[0;32m  11620\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n\u001b[0;32m  11621\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mall\u001b[39m(\n\u001b[0;32m  11622\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11626\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m  11627\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m> 11628\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_logical_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  11629\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbool_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m  11630\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, Series):\n\u001b[0;32m  11632\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\yunes\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:12208\u001b[0m, in \u001b[0;36mNDFrame._logical_func\u001b[1;34m(self, name, func, axis, bool_only, skipna, **kwargs)\u001b[0m\n\u001b[0;32m  12205\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_bool_data()\n\u001b[0;32m  12206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_reduce_axis1(name, func, skipna\u001b[38;5;241m=\u001b[39mskipna)\n\u001b[1;32m> 12208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m  12209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  12210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  12211\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  12212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  12213\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbool_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m  12214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilter_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbool\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m  12215\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yunes\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11562\u001b[0m, in \u001b[0;36mDataFrame._reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m  11558\u001b[0m     df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m  11560\u001b[0m \u001b[38;5;66;03m# After possibly _get_data and transposing, we are now in the\u001b[39;00m\n\u001b[0;32m  11561\u001b[0m \u001b[38;5;66;03m#  simple case where we can use BlockManager.reduce\u001b[39;00m\n\u001b[1;32m> 11562\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblk_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m  11563\u001b[0m out \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(res, axes\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m  11564\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m out\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboolean\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\yunes\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1500\u001b[0m, in \u001b[0;36mBlockManager.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m   1498\u001b[0m res_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m blk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks:\n\u001b[1;32m-> 1500\u001b[0m     nbs \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1501\u001b[0m     res_blocks\u001b[38;5;241m.\u001b[39mextend(nbs)\n\u001b[0;32m   1503\u001b[0m index \u001b[38;5;241m=\u001b[39m Index([\u001b[38;5;28;01mNone\u001b[39;00m])  \u001b[38;5;66;03m# placeholder\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yunes\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:404\u001b[0m, in \u001b[0;36mBlock.reduce\u001b[1;34m(self, func)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreduce\u001b[39m(\u001b[38;5;28mself\u001b[39m, func) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Block]:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;66;03m# We will apply the function and reshape the result into a single-row\u001b[39;00m\n\u001b[0;32m    401\u001b[0m     \u001b[38;5;66;03m#  Block with the same mgr_locs; squeezing will be done at a higher level\u001b[39;00m\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 404\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    407\u001b[0m         res_values \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[1;32mc:\\Users\\yunes\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:11481\u001b[0m, in \u001b[0;36mDataFrame._reduce.<locals>.blk_func\u001b[1;34m(values, axis)\u001b[0m\n\u001b[0;32m  11479\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray([result])\n\u001b[0;32m  11480\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m> 11481\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yunes\\anaconda3\\Lib\\site-packages\\pandas\\core\\nanops.py:581\u001b[0m, in \u001b[0;36mnanall\u001b[1;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;124;03mCheck if all elements along an axis evaluate to True.\u001b[39;00m\n\u001b[0;32m    552\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    575\u001b[0m \u001b[38;5;124;03mFalse\u001b[39;00m\n\u001b[0;32m    576\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miub\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;66;03m# GH#26032 fastpath\u001b[39;00m\n\u001b[0;32m    579\u001b[0m     \u001b[38;5;66;03m# error: Incompatible return value type (got \"Union[bool_, ndarray]\",\u001b[39;00m\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;66;03m# expected \"bool\")\u001b[39;00m\n\u001b[1;32m--> 581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mall\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[return-value]\u001b[39;00m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    584\u001b[0m     \u001b[38;5;66;03m# GH#34479\u001b[39;00m\n\u001b[0;32m    585\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    586\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m with datetime64 dtypes is deprecated and will raise in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    587\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfuture version. Use (obj != pd.Timestamp(0)).all() instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    588\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    589\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    590\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\yunes\\anaconda3\\Lib\\site-packages\\numpy\\core\\_methods.py:64\u001b[0m, in \u001b[0;36m_all\u001b[1;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_all\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# Parsing keyword arguments is currently fairly slow, so avoid it for now\u001b[39;00m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m where \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mumr_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m umr_all(a, axis, dtype, out, keepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for min_cardinality in min_cardinalities2:\n",
    "    classifier3 = LazyClassifierFCA3(max_counter_examples=1, min_cardinality=min_cardinality)\n",
    "    classifier3.fit(X_train, y_train)\n",
    "    y_pred3 = classifier3.predict(X_val)\n",
    "    print(f\"Metrics with min_cardinality = {min_cardinality}\")\n",
    "    evaluate_binary_classification(y_val, y_pred3)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics with min_cardinality = 20\n",
      "True Positive (TP): 40\n",
      "True Negative (TN): 103\n",
      "False Positive (FP): 20\n",
      "False Negative (FN): 29\n",
      "True Negative Rate (Specificity): 0.8374\n",
      "Negative Predictive Value (NPV): 0.7803\n",
      "False Positive Rate (FPR): 0.1626\n",
      "False Discovery Rate (FDR): 0.3333\n",
      "Accuracy: 0.7448\n",
      "Precision: 0.6667\n",
      "Recall (True Positive Rate): 0.5797\n",
      "F1 Score: 0.6202\n",
      "\n",
      "\n",
      "Metrics with min_cardinality = 22\n",
      "True Positive (TP): 40\n",
      "True Negative (TN): 102\n",
      "False Positive (FP): 21\n",
      "False Negative (FN): 29\n",
      "True Negative Rate (Specificity): 0.8293\n",
      "Negative Predictive Value (NPV): 0.7786\n",
      "False Positive Rate (FPR): 0.1707\n",
      "False Discovery Rate (FDR): 0.3443\n",
      "Accuracy: 0.7396\n",
      "Precision: 0.6557\n",
      "Recall (True Positive Rate): 0.5797\n",
      "F1 Score: 0.6154\n",
      "\n",
      "\n",
      "Metrics with min_cardinality = 24\n",
      "True Positive (TP): 39\n",
      "True Negative (TN): 101\n",
      "False Positive (FP): 22\n",
      "False Negative (FN): 30\n",
      "True Negative Rate (Specificity): 0.8211\n",
      "Negative Predictive Value (NPV): 0.7710\n",
      "False Positive Rate (FPR): 0.1789\n",
      "False Discovery Rate (FDR): 0.3607\n",
      "Accuracy: 0.7292\n",
      "Precision: 0.6393\n",
      "Recall (True Positive Rate): 0.5652\n",
      "F1 Score: 0.6000\n",
      "\n",
      "\n",
      "Metrics with min_cardinality = 26\n",
      "True Positive (TP): 34\n",
      "True Negative (TN): 101\n",
      "False Positive (FP): 22\n",
      "False Negative (FN): 35\n",
      "True Negative Rate (Specificity): 0.8211\n",
      "Negative Predictive Value (NPV): 0.7426\n",
      "False Positive Rate (FPR): 0.1789\n",
      "False Discovery Rate (FDR): 0.3929\n",
      "Accuracy: 0.7031\n",
      "Precision: 0.6071\n",
      "Recall (True Positive Rate): 0.4928\n",
      "F1 Score: 0.5440\n",
      "\n",
      "\n",
      "Metrics with min_cardinality = 28\n",
      "True Positive (TP): 37\n",
      "True Negative (TN): 102\n",
      "False Positive (FP): 21\n",
      "False Negative (FN): 32\n",
      "True Negative Rate (Specificity): 0.8293\n",
      "Negative Predictive Value (NPV): 0.7612\n",
      "False Positive Rate (FPR): 0.1707\n",
      "False Discovery Rate (FDR): 0.3621\n",
      "Accuracy: 0.7240\n",
      "Precision: 0.6379\n",
      "Recall (True Positive Rate): 0.5362\n",
      "F1 Score: 0.5827\n",
      "\n",
      "\n",
      "Metrics with min_cardinality = 30\n",
      "True Positive (TP): 39\n",
      "True Negative (TN): 101\n",
      "False Positive (FP): 22\n",
      "False Negative (FN): 30\n",
      "True Negative Rate (Specificity): 0.8211\n",
      "Negative Predictive Value (NPV): 0.7710\n",
      "False Positive Rate (FPR): 0.1789\n",
      "False Discovery Rate (FDR): 0.3607\n",
      "Accuracy: 0.7292\n",
      "Precision: 0.6393\n",
      "Recall (True Positive Rate): 0.5652\n",
      "F1 Score: 0.6000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for min_cardinality in min_cardinalities:\n",
    "    classifier3 = LazyClassifierFCA3(max_counter_examples=1, min_cardinality=min_cardinality)\n",
    "    classifier3.fit(X_train, y_train)\n",
    "    y_pred3 = classifier3.predict(X_val)\n",
    "    print(f\"Metrics with min_cardinality = {min_cardinality}\")\n",
    "    evaluate_binary_classification(y_val, y_pred3)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier3 = LazyClassifierFCA3(max_counter_examples=1, min_cardinality=30)\n",
    "classifier3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 51.8 s\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred3 = classifier3.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive (TP): 39\n",
      "True Negative (TN): 101\n",
      "False Positive (FP): 22\n",
      "False Negative (FN): 30\n",
      "True Negative Rate (Specificity): 0.8211\n",
      "Negative Predictive Value (NPV): 0.7710\n",
      "False Positive Rate (FPR): 0.1789\n",
      "False Discovery Rate (FDR): 0.3607\n",
      "Accuracy: 0.7292\n",
      "Precision: 0.6393\n",
      "Recall (True Positive Rate): 0.5652\n",
      "F1 Score: 0.6000\n"
     ]
    }
   ],
   "source": [
    "evaluate_binary_classification(y_val, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LazyClassifierFCA4:\n",
    "#     def __init__(self):\n",
    "#         self.X_train = None\n",
    "#         self.y_train = None\n",
    "\n",
    "#     def fit(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
    "#         self.X_train = X_train\n",
    "#         self.y_train = y_train\n",
    "        \n",
    "#     def classify_sample(self, sample: pd.Series) -> Any:\n",
    "#         X_train_positive = self.X_train[y_train['outcome'] == 1]\n",
    "#         X_train_negative = self.X_train[y_train['outcome'] == 0]\n",
    "        \n",
    "#         positive_classifiers = 0\n",
    "#         negative_classifiers = 0\n",
    "        \n",
    "#         max_pos_intersection = 0\n",
    "#         n_max_pos_intersections = 0\n",
    "\n",
    "#         max_neg_intersection = 0\n",
    "#         n_max_neg_intersections = 0\n",
    "\n",
    "#         for _, pos_sample in X_train_positive.iterrows():\n",
    "#             intersection = sample & pos_sample\n",
    "#             if intersection.sum() > max_pos_intersection:\n",
    "#                 max_pos_intersection = intersection.sum()\n",
    "#                 n_max_pos_intersections = 1\n",
    "#             elif intersection.sum() == max_pos_intersection:\n",
    "#                 n_max_pos_intersections += 1\n",
    "\n",
    "#         # Check for negative classifiers by intersecting sample with each negative object\n",
    "#         for _, neg_sample in X_train_negative.iterrows():\n",
    "#             intersection = sample & neg_sample\n",
    "#             if intersection.sum() > max_neg_intersection:\n",
    "#                 max_neg_intersection = intersection.sum()\n",
    "#                 n_max_neg_intersections = 1\n",
    "#             elif intersection.sum() == max_neg_intersection:\n",
    "#                 n_max_neg_intersections += 1\n",
    "\n",
    "#         if max_pos_intersection > max_neg_intersection:\n",
    "#             return 1\n",
    "#         elif max_neg_intersection > max_pos_intersection:\n",
    "#             return 0\n",
    "#         else:\n",
    "#             if n_max_pos_intersections > n_max_neg_intersections:\n",
    "#                 return 1\n",
    "#             elif n_max_neg_intersections > n_max_pos_intersections:\n",
    "#                 return 0\n",
    "#             else:\n",
    "#                 return 1\n",
    "\n",
    "\n",
    "#     def predict(self, X_test: pd.DataFrame) -> List[Any]:\n",
    "#         # List to store predictions for each test sample\n",
    "#         predictions = []\n",
    "        \n",
    "#         # Iterate through each sample in X_test\n",
    "#         for _, sample in X_test.iterrows():\n",
    "#             # Classify the sample and append the result to predictions\n",
    "#             prediction= self.classify_sample(sample)\n",
    "#             predictions.append(prediction)\n",
    "        \n",
    "#         return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LazyClassifierFCA4:\n",
    "    def __init__(self):\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        # self.max_counter_examples = max_counter_examples\n",
    "\n",
    "    def fit(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def classify_sample(self, sample: pd.Series) -> Any:\n",
    "        # Split X_train into positive and negative classes\n",
    "        X_train_positive = self.X_train[y_train['outcome'] == 1]\n",
    "        X_train_negative = self.X_train[y_train['outcome'] == 0]\n",
    "        \n",
    "        positive_classifiers = 0\n",
    "        negative_classifiers = 0\n",
    "        pos = 0\n",
    "        neg = 0\n",
    "        \n",
    "        # Function to check if intersection with a train sample is a positive classifier\n",
    "        def is_positive_classifier(intersection):\n",
    "            # Find samples in X_train_positive that contain the intersection\n",
    "            num_positive = ((X_train_positive | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            num_negative = ((X_train_negative | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            return num_negative < 1 and num_positive > 1\n",
    "        \n",
    "        # Function to check if intersection is a negative classifier\n",
    "        def is_negative_classifier(intersection):\n",
    "            # Find samples in X_train_negative that contain the intersection\n",
    "            num_positive = ((X_train_positive | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            num_negative = ((X_train_negative | (~intersection.astype(bool)).astype(np.int32)) == True).all(axis=1).sum()\n",
    "            return num_positive < 1 and num_negative > 1\n",
    "        \n",
    "        # Check for positive classifiers by intersecting sample with each positive object\n",
    "        for _, pos_sample in X_train_positive.iterrows():\n",
    "            intersection = sample & pos_sample\n",
    "            if is_positive_classifier(intersection):\n",
    "                pos += intersection.sum() / sample.shape[0]\n",
    "                positive_classifiers += 1\n",
    "\n",
    "        # Check for negative classifiers by intersecting sample with each negative object\n",
    "        for _, neg_sample in X_train_negative.iterrows():\n",
    "            intersection = sample & neg_sample\n",
    "            if is_negative_classifier(intersection):\n",
    "                neg += intersection.sum() / sample.shape[0]\n",
    "                negative_classifiers += 1\n",
    "\n",
    "        # Determine the class based on the number of classifiers\n",
    "        if pos / X_train_positive.shape[0] > neg / X_train_negative.shape[0]:\n",
    "            # print(f\"sample {sample.name} is classified as 1, {positive_classifiers=}, {negative_classifiers=}\")\n",
    "            return 1, positive_classifiers  # Predict positive\n",
    "            \n",
    "        elif neg / X_train_negative.shape[0] > pos / X_train_positive.shape[0]:\n",
    "            # print(f\"sample {sample.name} is classified as 0, {positive_classifiers=}, {negative_classifiers=}\")\n",
    "            return 0, negative_classifiers  # Predict negative\n",
    "\n",
    "        else:\n",
    "            # If equal, you can decide on a rule, like defaulting to 0 or 1, or returning 'undetermined'\n",
    "            # print(f\"sample {sample.name} is classified as 1, default, {positive_classifiers=}, {negative_classifiers=}\")\n",
    "        \n",
    "            return 1, positive_classifiers  # or 0, depending on the choice\n",
    "\n",
    "\n",
    "    def predict(self, X_test: pd.DataFrame) -> List[Any]:\n",
    "        # List to store predictions for each test sample\n",
    "        predictions = []\n",
    "        classifiers = []\n",
    "        \n",
    "        # Iterate through each sample in X_test\n",
    "        for _, sample in X_test.iterrows():\n",
    "            # Classify the sample and append the result to predictions\n",
    "            prediction, n_clfs = self.classify_sample(sample)\n",
    "            predictions.append(prediction)\n",
    "            classifiers.append(n_clfs)\n",
    "        \n",
    "        self.avg_n_clfs = np.mean(classifiers)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier4 = LazyClassifierFCA4()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 56.3 s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred4 = classifier4.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109.04166666666667"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier4.avg_n_clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive (TP): 40\n",
      "True Negative (TN): 102\n",
      "False Positive (FP): 21\n",
      "False Negative (FN): 29\n",
      "True Negative Rate (Specificity): 0.8293\n",
      "Negative Predictive Value (NPV): 0.7786\n",
      "False Positive Rate (FPR): 0.1707\n",
      "False Discovery Rate (FDR): 0.3443\n",
      "Accuracy: 0.7396\n",
      "Precision: 0.6557\n",
      "Recall (True Positive Rate): 0.5797\n",
      "F1 Score: 0.6154\n"
     ]
    }
   ],
   "source": [
    "evaluate_binary_classification(y_val, y_pred4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "True Positive (TP): 40\n",
    "\n",
    "True Negative (TN): 102\n",
    "\n",
    "False Positive (FP): 21\n",
    "\n",
    "False Negative (FN): 29\n",
    "\n",
    "True Negative Rate (Specificity): 0.8293\n",
    "\n",
    "Negative Predictive Value (NPV): 0.7786\n",
    "\n",
    "False Positive Rate (FPR): 0.1707\n",
    "\n",
    "False Discovery Rate (FDR): 0.\n",
    "\n",
    "Accuracy: 0.7396\n",
    "\n",
    "Precision: 0.6557\n",
    "\n",
    "Recall (True Positive Rate): 0.5797\n",
    "\n",
    "F1 Score: 0.6154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
